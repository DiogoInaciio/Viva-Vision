# Viva-Vision ğŸŒŸ

## O que Ã© o projeto

**Viva-Vision** Ã© um projeto inovador de InteligÃªncia Artificial voltado para a acessibilidade, especialmente para pessoas com deficiÃªncia visual. Este sistema utiliza reconhecimento de imagem para fornecer descriÃ§Ãµes detalhadas do ambiente ao redor do usuÃ¡rio, atravÃ©s de uma cÃ¢mera conectada a um alto-falante. AlÃ©m de descrever cenÃ¡rios em tempo real, o Viva-Vision tambÃ©m funciona como um chatbot generativo, permitindo uma interaÃ§Ã£o mais rica e informativa. ğŸ“·ğŸ”Š

## Por que essa escolha

A escolha deste projeto Ã© motivada pela necessidade de oferecer mais autonomia e qualidade de vida para pessoas com deficiÃªncia visual. Com o Viva-Vision, queremos proporcionar uma maneira de "enxergar" o mundo ao redor, utilizando tecnologia de ponta para descrever o ambiente e permitir interaÃ§Ãµes significativas atravÃ©s de conversas. ğŸŒğŸ’¬

## Como pode ajudar

O Viva-Vision permite que pessoas com deficiÃªncia visual obtenham descriÃ§Ãµes detalhadas e precisas do que estÃ¡ acontecendo ao seu redor em tempo real. Isso ajuda a melhorar a percepÃ§Ã£o espacial e a compreensÃ£o do ambiente, oferecendo uma ferramenta poderosa para aumentar a autonomia e a integraÃ§Ã£o social. AlÃ©m disso, a funÃ§Ã£o de chatbot generativo permite interaÃ§Ãµes conversacionais que enriquecem ainda mais a experiÃªncia do usuÃ¡rio. ğŸŒŸğŸ¤–

## Tecnologias Utilizadas

- **Reconhecimento de Imagem**: Utiliza o modelo BLIP para gerar descriÃ§Ãµes das imagens capturadas pela cÃ¢mera. ğŸ–¼ï¸
- **Processamento de Linguagem Natural (NLP)**: Utiliza a OpenAI API para gerar respostas conversacionais. ğŸ§ 
- **TraduÃ§Ã£o**: Google Translator Ã© usado para traduzir as descriÃ§Ãµes para o idioma desejado. ğŸŒ
- **SÃ­ntese de Fala**: Pyttsx3 para converter texto em fala e fornecer feedback auditivo ao usuÃ¡rio. ğŸ™ï¸
- **Reconhecimento de Fala**: SpeechRecognition para captar e interpretar comandos de voz. ğŸ¤

## Requisitos

- **Python 3.7+** ğŸ
- **Bibliotecas Python**:
  - OpenCV ğŸ“¸
  - Pillow ğŸ–¼ï¸
  - deep_translator ğŸŒ
  - pyttsx3 ğŸ™ï¸
  - transformers ğŸ¤–
  - openai ğŸŒŸ
  - SpeechRecognition ğŸ¤

## Como Funciona

1. **InicializaÃ§Ã£o**:
   - O cÃ³digo inicializa o cliente da OpenAI, o motor de sÃ­ntese de voz, e o tradutor. âš™ï¸

2. **Carregamento do Modelo**:
   - Carrega o modelo BLIP para descriÃ§Ã£o de imagens. ğŸ“š

3. **AnÃ¡lise de Imagem**:
   - Captura imagens da cÃ¢mera, gera uma legenda para a imagem, traduz a descriÃ§Ã£o e a reproduz em voz alta. ğŸ“·â¡ï¸ğŸ“ğŸ”Š

4. **Reconhecimento de Fala**:
   - Capta o Ã¡udio do usuÃ¡rio, reconhece a fala e responde com base no comando recebido. ğŸ¤â¡ï¸ğŸ—£ï¸

5. **InteraÃ§Ã£o com o Chatbot**:
   - Envia perguntas para o modelo da OpenAI e reproduz as respostas em voz alta. ğŸ’¬ğŸ”„ğŸ”Š

## Como Contribuir

ContribuiÃ§Ãµes sÃ£o bem-vindas! Se vocÃª deseja colaborar com o Viva-Vision, siga estas etapas:

1. FaÃ§a um fork do repositÃ³rio. ğŸ´
2. Crie uma branch para suas alteraÃ§Ãµes. ğŸŒ¿
3. Realize suas modificaÃ§Ãµes e adicione testes, se necessÃ¡rio. ğŸ› ï¸
4. Envie um pull request com uma descriÃ§Ã£o detalhada das mudanÃ§as. ğŸš€

## Uso

Para executar o Viva-Vision:

1. Instale as dependÃªncias necessÃ¡rias:
   ```bash
   pip install opencv-python Pillow deep-translator pyttsx3 transformers openai SpeechRecognition
